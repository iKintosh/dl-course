{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jcxpU7lw-k89",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Segmentation task\n",
    "\n",
    "Hi! It's a segmentation task baseline notebook.\n",
    "It include a data reader, baseline model and submission generator.\n",
    "\n",
    "You should use GPU to train your model, so we recommend using [Kaggle Notebooks](https://www.kaggle.com/docs/notebooks).\n",
    "To get maximum score of the task, your model should have IoU greater than `0.8`.\n",
    "\n",
    "You can use everything, that suits into the rules in `README.md`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XoX11UWh-uIJ",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils import data\n",
    "\n",
    "import catalyst\n",
    "from catalyst import dl\n",
    "from catalyst.utils import metrics, imread, set_global_seed\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "import albumentations as albu\n",
    "from albumentations.pytorch import ToTensorV2 as ToTensor\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "SaqjtWTwlXAM"
   },
   "outputs": [],
   "source": [
    "set_global_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FO6rmbPvknSQ",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Dataset\n",
    "\n",
    "Load train data. Don't forget to add test data. Use test data, to compare methods/models/etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_path = Path().cwd().parent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "iVn6EFYFEFxB",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train_image_path = local_path / 'data3'/ Path(\"train\") / \"images\"\n",
    "train_mask_path = local_path / 'data3'/ Path(\"train\") / \"masks\"\n",
    "ALL_IMAGES = sorted(train_image_path.glob(\"*.png\"))\n",
    "ALL_MASKS = sorted(train_mask_path.glob(\"*.png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "n-po_PN9-xXc"
   },
   "outputs": [],
   "source": [
    "class SegmentationDataset(Dataset):\n",
    "    def __init__(self, images=None, masks=None, transforms=None) -> None:\n",
    "        self.images = images\n",
    "        self.masks = masks\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx: int) -> dict:\n",
    "        image_path = self.images[idx]\n",
    "        image = imread(image_path)\n",
    "\n",
    "        result = {\"image\": image}\n",
    "\n",
    "        if self.masks is not None:\n",
    "            result[\"mask\"] = imread(self.masks[idx]).mean(2) // 255\n",
    "\n",
    "        if self.transforms is not None:\n",
    "            result = self.transforms(**result)\n",
    "            if result.get(\"mask\", None) is not None:\n",
    "                result[\"mask\"] = result[\"mask\"].unsqueeze(0)\n",
    "\n",
    "        result[\"filename\"] = image_path.name\n",
    "        result[\"image size\"] = image.shape[:2]\n",
    "\n",
    "        return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i4Ra4BVlkEXD",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Augmentations\n",
    "\n",
    "To train an accurate model for a segmentation task, you need a lot of data.\n",
    "Use data augmentations to simulate a bigger dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "QUAVP6dUEFxN",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "IMAGE_SIZE = 256\n",
    "train_transform = albu.Compose([\n",
    "    albu.HorizontalFlip(p=0.3),\n",
    "    albu.VerticalFlip(p=0.3),\n",
    "    albu.RandomRotate90(p=0.3),\n",
    "    albu.Resize(IMAGE_SIZE, IMAGE_SIZE),\n",
    "    albu.RandomResizedCrop(IMAGE_SIZE, IMAGE_SIZE, p=0.3),\n",
    "    albu.Normalize(),\n",
    "    ToTensor()\n",
    "])\n",
    "\n",
    "valid_transform = albu.Compose([\n",
    "    albu.Resize(IMAGE_SIZE, IMAGE_SIZE),\n",
    "    albu.RandomResizedCrop(IMAGE_SIZE, IMAGE_SIZE, p=0.25),\n",
    "    albu.Normalize(),\n",
    "    ToTensor()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "kxI3m4fPkEU3"
   },
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "num_workers = 4\n",
    "\n",
    "indices = np.arange(len(ALL_IMAGES))\n",
    "\n",
    "train_indices, valid_indices = train_test_split(\n",
    "    indices, test_size=0.1, random_state=42, shuffle=True\n",
    ")\n",
    "\n",
    "np_images = np.array(ALL_IMAGES)\n",
    "np_masks = np.array(ALL_MASKS)\n",
    "\n",
    "train_dataset = SegmentationDataset(\n",
    "    images = np_images.tolist(),\n",
    "    masks = np_masks.tolist(),\n",
    "    transforms = train_transform\n",
    ")\n",
    "loaders = {\n",
    "    \"train\": DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=num_workers,\n",
    "        drop_last=True,\n",
    "    ),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f-i6VRW4EFxV"
   },
   "source": [
    "Our current baseline model is `U-Net`.\n",
    "You can do anything with it: add pretrained backbone, make model wider or deeper or change a model architecture.\n",
    "You can use `torchvision` module to create a backbone, but not a whole model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "iyw0JH3R-z6m"
   },
   "outputs": [],
   "source": [
    "class Baseline(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.down_1 = self.make_down_layer_(3, 64)\n",
    "        self.down_2 = self.make_down_layer_(64, 128)\n",
    "        self.down_3 = self.make_down_layer_(128, 256)\n",
    "        self.down_4 = self.make_down_layer_(256, 512)\n",
    "\n",
    "        self.up_1 = self.make_up_layer_(512, 256)\n",
    "        self.up_2 = self.make_up_layer_(256, 128)\n",
    "        self.up_3 = self.make_up_layer_(128, 64)\n",
    "        self.up_4 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(64, 1, kernel_size=3, padding=1, stride=2, output_padding=1)\n",
    "        )\n",
    "\n",
    "    def make_down_layer_(self, in_channels, out_channels):\n",
    "        return nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        )\n",
    "\n",
    "    def make_up_layer_(self, in_channels, out_channels):\n",
    "        return nn.ModuleList(\n",
    "            [\n",
    "                nn.ConvTranspose2d(\n",
    "                    in_channels,\n",
    "                    out_channels,\n",
    "                    kernel_size=3,\n",
    "                    stride=2,\n",
    "                    padding=1,\n",
    "                    output_padding=1,\n",
    "                ),\n",
    "                nn.BatchNorm2d(2 * out_channels),\n",
    "                nn.LeakyReLU(),\n",
    "                nn.ConvTranspose2d(\n",
    "                    2 * out_channels,\n",
    "                    out_channels,\n",
    "                    kernel_size=3,\n",
    "                    stride=1,\n",
    "                    padding=1,\n",
    "                ),\n",
    "                nn.BatchNorm2d(out_channels),\n",
    "                nn.LeakyReLU(),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    def forward(self, image):\n",
    "        x_1 = self.down_1(image)\n",
    "        x_2 = self.down_2(x_1)\n",
    "        x_3 = self.down_3(x_2)\n",
    "        x_4 = self.down_4(x_3)\n",
    "\n",
    "        u_1 = self.up_1[0](x_4)\n",
    "        u_1 = torch.cat([x_3, u_1], axis=1)\n",
    "        for m in self.up_1[1:]:\n",
    "            u_1 = m(u_1)\n",
    "        \n",
    "        u_2 = self.up_2[0](u_1)\n",
    "        u_2 = torch.cat([x_2, u_2], axis=1)\n",
    "        for m in self.up_2[1:]:\n",
    "            u_2 = m(u_2)\n",
    "\n",
    "        u_3 = self.up_3[0](u_2)\n",
    "        u_3 = torch.cat([x_1, u_3], axis=1)\n",
    "        for m in self.up_3[1:]:\n",
    "            u_3 = m(u_3)\n",
    "\n",
    "        return self.up_4(u_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "uRKiYSE0-zxs"
   },
   "outputs": [],
   "source": [
    "from catalyst.contrib.nn import DiceLoss, IoULoss\n",
    "from catalyst.dl.runner import SupervisedRunner\n",
    "from torch.nn.functional import interpolate\n",
    "\n",
    "\n",
    "class SegmentationRunner(SupervisedRunner):\n",
    "    def predict_batch(self, batch):\n",
    "        prediction = {\"filename\": batch[\"filename\"]}\n",
    "        masks = self.model(batch[self.input_key].to(self.device))\n",
    "        image_size = list(zip(*batch[\"image size\"]))\n",
    "        prediction[\"mask\"] = [\n",
    "            interpolate(mask.unsqueeze(0), image_size).squeeze(0)\n",
    "            for mask, image_size in zip(masks, image_size)\n",
    "        ]\n",
    "        return prediction\n",
    "\n",
    "# we have multiple criterions\n",
    "model = Baseline()\n",
    "criterion = {\n",
    "    \"dice\": DiceLoss(),\n",
    "    \"iou\": IoULoss(),\n",
    "    \"bce\": nn.BCEWithLogitsLoss()\n",
    "}\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=3e-4, weight_decay=0.0003)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor=0.25, patience=3, min_lr=1e-8, mode='max')\n",
    "\n",
    "runner = SegmentationRunner(input_key=\"image\", input_target_key=\"mask\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "L2bR8k7y-48I"
   },
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    dl.CriterionCallback(\n",
    "        input_key=\"mask\", prefix=\"loss_dice\", criterion_key=\"dice\"\n",
    "    ),\n",
    "    dl.CriterionCallback(\n",
    "        input_key=\"mask\", prefix=\"loss_iou\", criterion_key=\"iou\"\n",
    "    ),\n",
    "    dl.CriterionCallback(\n",
    "        input_key=\"mask\", prefix=\"loss_bce\", criterion_key=\"bce\"\n",
    "    ),\n",
    "    dl.MetricAggregationCallback(\n",
    "        prefix=\"loss\",\n",
    "        mode=\"weighted_sum\",\n",
    "        metrics={\"loss_dice\": 1.0, \"loss_iou\": 1.0, \"loss_bce\": 0.8},\n",
    "    ),\n",
    "    dl.DiceCallback(input_key=\"mask\"),\n",
    "    dl.IouCallback(input_key=\"mask\"),\n",
    "    dl.EarlyStoppingCallback(\n",
    "            patience=7,\n",
    "            metric=\"iou\",\n",
    "            minimize=False,\n",
    "            min_delta=1e-4,\n",
    "        )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "id": "YCKPbrUxm6tY"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/analekseev/.cache/pypoetry/virtualenvs/dl-course-SIh-1RzJ-py3.8/lib/python3.8/site-packages/catalyst/experiments/experiment.py:219: UserWarning:\n",
      "\n",
      "Attention, there is only one dataloader - train\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "1/100 * Epoch (train):   0% 0/51 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/analekseev/.cache/pypoetry/virtualenvs/dl-course-SIh-1RzJ-py3.8/lib/python3.8/site-packages/catalyst/callbacks/optimizer.py:140: UserWarning:\n",
      "\n",
      "This overload of add is deprecated:\n",
      "\tadd(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd(Tensor other, *, Number alpha) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:766.)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/100 * Epoch (train): 100% 51/51 [00:17<00:00,  2.90it/s, dice=0.832, iou=0.713, loss=0.654, loss_bce=0.249, loss_dice=0.168, loss_iou=0.287]\n",
      "[2020-10-18 12:38:00,249] \n",
      "1/100 * Epoch 1 (_base): lr=0.0003 | momentum=0.9000\n",
      "1/100 * Epoch 1 (train): dice=0.7344 | iou=0.5894 | loss=0.9718 | loss_bce=0.3695 | loss_dice=0.2656 | loss_iou=0.4106\n",
      "2/100 * Epoch (train): 100% 51/51 [00:17<00:00,  2.93it/s, dice=0.779, iou=0.638, loss=0.871, loss_bce=0.361, loss_dice=0.221, loss_iou=0.362]\n",
      "[2020-10-18 12:38:18,000] \n",
      "2/100 * Epoch 2 (_base): lr=0.0003 | momentum=0.9000\n",
      "2/100 * Epoch 2 (train): dice=0.7981 | iou=0.6686 | loss=0.7725 | loss_bce=0.2989 | loss_dice=0.2019 | loss_iou=0.3314\n",
      "3/100 * Epoch (train): 100% 51/51 [00:17<00:00,  2.88it/s, dice=0.876, iou=0.779, loss=0.492, loss_bce=0.184, loss_dice=0.124, loss_iou=0.221]\n",
      "[2020-10-18 12:38:42,057] \n",
      "3/100 * Epoch 3 (_base): lr=0.0003 | momentum=0.9000\n",
      "3/100 * Epoch 3 (train): dice=0.8224 | iou=0.7014 | loss=0.6821 | loss_bce=0.2575 | loss_dice=0.1776 | loss_iou=0.2986\n",
      "4/100 * Epoch (train): 100% 51/51 [00:17<00:00,  2.85it/s, dice=0.794, iou=0.658, loss=0.720, loss_bce=0.215, loss_dice=0.206, loss_iou=0.342]\n",
      "[2020-10-18 12:39:00,897] \n",
      "4/100 * Epoch 4 (_base): lr=0.0003 | momentum=0.9000\n",
      "4/100 * Epoch 4 (train): dice=0.8300 | iou=0.7130 | loss=0.6608 | loss_bce=0.2547 | loss_dice=0.1700 | loss_iou=0.2870\n",
      "5/100 * Epoch (train): 100% 51/51 [00:17<00:00,  2.85it/s, dice=0.902, iou=0.822, loss=0.361, loss_bce=0.106, loss_dice=0.098, loss_iou=0.178]\n",
      "[2020-10-18 12:39:19,706] \n",
      "5/100 * Epoch 5 (_base): lr=0.0003 | momentum=0.9000\n",
      "5/100 * Epoch 5 (train): dice=0.8431 | iou=0.7321 | loss=0.6188 | loss_bce=0.2425 | loss_dice=0.1569 | loss_iou=0.2679\n",
      "6/100 * Epoch (train): 100% 51/51 [00:18<00:00,  2.79it/s, dice=0.866, iou=0.764, loss=0.519, loss_bce=0.187, loss_dice=0.134, loss_iou=0.236]\n",
      "[2020-10-18 12:39:39,232] \n",
      "6/100 * Epoch 6 (_base): lr=0.0003 | momentum=0.9000\n",
      "6/100 * Epoch 6 (train): dice=0.8481 | iou=0.7384 | loss=0.6102 | loss_bce=0.2457 | loss_dice=0.1519 | loss_iou=0.2616\n",
      "7/100 * Epoch (train): 100% 51/51 [00:18<00:00,  2.79it/s, dice=0.924, iou=0.858, loss=0.296, loss_bce=0.097, loss_dice=0.076, loss_iou=0.142]\n",
      "[2020-10-18 12:39:59,372] \n",
      "7/100 * Epoch 7 (_base): lr=0.0003 | momentum=0.9000\n",
      "7/100 * Epoch 7 (train): dice=0.8548 | iou=0.7496 | loss=0.5780 | loss_bce=0.2280 | loss_dice=0.1452 | loss_iou=0.2504\n",
      "8/100 * Epoch (train): 100% 51/51 [00:18<00:00,  2.78it/s, dice=0.906, iou=0.828, loss=0.402, loss_bce=0.170, loss_dice=0.094, loss_iou=0.172]\n",
      "[2020-10-18 12:40:19,504] \n",
      "8/100 * Epoch 8 (_base): lr=0.0003 | momentum=0.9000\n",
      "8/100 * Epoch 8 (train): dice=0.8634 | iou=0.7618 | loss=0.5419 | loss_bce=0.2088 | loss_dice=0.1366 | loss_iou=0.2382\n",
      "9/100 * Epoch (train): 100% 51/51 [00:18<00:00,  2.77it/s, dice=0.846, iou=0.734, loss=0.629, loss_bce=0.261, loss_dice=0.154, loss_iou=0.266]\n",
      "[2020-10-18 12:40:38,825] \n",
      "9/100 * Epoch 9 (_base): lr=0.0003 | momentum=0.9000\n",
      "9/100 * Epoch 9 (train): dice=0.8666 | iou=0.7674 | loss=0.5422 | loss_bce=0.2203 | loss_dice=0.1334 | loss_iou=0.2326\n",
      "10/100 * Epoch (train): 100% 51/51 [00:18<00:00,  2.76it/s, dice=0.901, iou=0.819, loss=0.384, loss_bce=0.130, loss_dice=0.099, loss_iou=0.181]\n",
      "[2020-10-18 12:40:58,194] \n",
      "10/100 * Epoch 10 (_base): lr=0.0003 | momentum=0.9000\n",
      "10/100 * Epoch 10 (train): dice=0.8727 | iou=0.7762 | loss=0.5167 | loss_bce=0.2070 | loss_dice=0.1273 | loss_iou=0.2238\n",
      "11/100 * Epoch (train): 100% 51/51 [00:18<00:00,  2.76it/s, dice=0.873, iou=0.775, loss=0.528, loss_bce=0.220, loss_dice=0.127, loss_iou=0.225]\n",
      "[2020-10-18 12:41:17,611] \n",
      "11/100 * Epoch 11 (_base): lr=0.0003 | momentum=0.9000\n",
      "11/100 * Epoch 11 (train): dice=0.8826 | iou=0.7931 | loss=0.4747 | loss_bce=0.1880 | loss_dice=0.1174 | loss_iou=0.2069\n",
      "12/100 * Epoch (train): 100% 51/51 [00:18<00:00,  2.74it/s, dice=0.882, iou=0.789, loss=0.484, loss_bce=0.193, loss_dice=0.118, loss_iou=0.211]\n",
      "[2020-10-18 12:41:37,131] \n",
      "12/100 * Epoch 12 (_base): lr=0.0003 | momentum=0.9000\n",
      "12/100 * Epoch 12 (train): dice=0.8759 | iou=0.7825 | loss=0.5101 | loss_bce=0.2106 | loss_dice=0.1241 | loss_iou=0.2175\n",
      "13/100 * Epoch (train): 100% 51/51 [00:18<00:00,  2.74it/s, dice=0.890, iou=0.802, loss=0.561, loss_bce=0.315, loss_dice=0.110, loss_iou=0.198]\n",
      "[2020-10-18 12:41:56,307] \n",
      "13/100 * Epoch 13 (_base): lr=0.0003 | momentum=0.9000\n",
      "13/100 * Epoch 13 (train): dice=0.8942 | iou=0.8102 | loss=0.4354 | loss_bce=0.1748 | loss_dice=0.1058 | loss_iou=0.1898\n",
      "14/100 * Epoch (train): 100% 51/51 [00:18<00:00,  2.73it/s, dice=0.909, iou=0.832, loss=0.383, loss_bce=0.155, loss_dice=0.091, loss_iou=0.168]\n",
      "[2020-10-18 12:42:15,883] \n",
      "14/100 * Epoch 14 (_base): lr=0.0003 | momentum=0.9000\n",
      "14/100 * Epoch 14 (train): dice=0.8837 | iou=0.7947 | loss=0.4716 | loss_bce=0.1876 | loss_dice=0.1163 | loss_iou=0.2053\n",
      "15/100 * Epoch (train): 100% 51/51 [00:18<00:00,  2.72it/s, dice=0.910, iou=0.835, loss=0.392, loss_bce=0.172, loss_dice=0.090, loss_iou=0.165]\n",
      "[2020-10-18 12:42:35,202] \n",
      "15/100 * Epoch 15 (_base): lr=0.0003 | momentum=0.9000\n",
      "15/100 * Epoch 15 (train): dice=0.8925 | iou=0.8077 | loss=0.4456 | loss_bce=0.1822 | loss_dice=0.1075 | loss_iou=0.1923\n",
      "16/100 * Epoch (train): 100% 51/51 [00:18<00:00,  2.71it/s, dice=0.845, iou=0.731, loss=0.686, loss_bce=0.328, loss_dice=0.155, loss_iou=0.269]\n",
      "[2020-10-18 12:42:54,621] \n",
      "16/100 * Epoch 16 (_base): lr=0.0003 | momentum=0.9000\n",
      "16/100 * Epoch 16 (train): dice=0.8885 | iou=0.8017 | loss=0.4646 | loss_bce=0.1935 | loss_dice=0.1115 | loss_iou=0.1983\n",
      "17/100 * Epoch (train): 100% 51/51 [00:18<00:00,  2.72it/s, dice=0.915, iou=0.844, loss=0.356, loss_bce=0.144, loss_dice=0.085, loss_iou=0.156]\n",
      "[2020-10-18 12:43:14,017] \n",
      "17/100 * Epoch 17 (_base): lr=7.500e-05 | momentum=0.9000\n",
      "17/100 * Epoch 17 (train): dice=0.8891 | iou=0.8030 | loss=0.4594 | loss_bce=0.1893 | loss_dice=0.1109 | loss_iou=0.1970\n",
      "18/100 * Epoch (train): 100% 51/51 [00:18<00:00,  2.70it/s, dice=0.892, iou=0.804, loss=0.499, loss_bce=0.244, loss_dice=0.108, loss_iou=0.196]\n",
      "[2020-10-18 12:43:33,464] \n",
      "18/100 * Epoch 18 (_base): lr=7.500e-05 | momentum=0.9000\n",
      "18/100 * Epoch 18 (train): dice=0.9032 | iou=0.8254 | loss=0.4046 | loss_bce=0.1664 | loss_dice=0.0968 | loss_iou=0.1746\n",
      "19/100 * Epoch (train): 100% 51/51 [00:18<00:00,  2.70it/s, dice=0.956, iou=0.916, loss=0.186, loss_bce=0.073, loss_dice=0.044, loss_iou=0.084]\n",
      "[2020-10-18 12:43:53,343] \n",
      "19/100 * Epoch 19 (_base): lr=7.500e-05 | momentum=0.9000\n",
      "19/100 * Epoch 19 (train): dice=0.9125 | iou=0.8404 | loss=0.3651 | loss_bce=0.1475 | loss_dice=0.0875 | loss_iou=0.1596\n",
      "20/100 * Epoch (train): 100% 51/51 [00:18<00:00,  2.71it/s, dice=0.926, iou=0.863, loss=0.290, loss_bce=0.100, loss_dice=0.074, loss_iou=0.137]\n",
      "[2020-10-18 12:44:13,166] \n",
      "20/100 * Epoch 20 (_base): lr=7.500e-05 | momentum=0.9000\n",
      "20/100 * Epoch 20 (train): dice=0.9061 | iou=0.8315 | loss=0.3847 | loss_bce=0.1529 | loss_dice=0.0939 | loss_iou=0.1685\n",
      "21/100 * Epoch (train): 100% 51/51 [00:19<00:00,  2.68it/s, dice=0.952, iou=0.909, loss=0.192, loss_bce=0.066, loss_dice=0.048, loss_iou=0.091]\n",
      "[2020-10-18 12:44:32,803] \n",
      "21/100 * Epoch 21 (_base): lr=7.500e-05 | momentum=0.9000\n",
      "21/100 * Epoch 21 (train): dice=0.9073 | iou=0.8324 | loss=0.3850 | loss_bce=0.1558 | loss_dice=0.0927 | loss_iou=0.1676\n",
      "22/100 * Epoch (train): 100% 51/51 [00:18<00:00,  2.70it/s, dice=0.927, iou=0.864, loss=0.291, loss_bce=0.104, loss_dice=0.073, loss_iou=0.136]\n",
      "[2020-10-18 12:44:52,281] \n",
      "22/100 * Epoch 22 (_base): lr=7.500e-05 | momentum=0.9000\n",
      "22/100 * Epoch 22 (train): dice=0.9104 | iou=0.8375 | loss=0.3732 | loss_bce=0.1514 | loss_dice=0.0896 | loss_iou=0.1625\n",
      "23/100 * Epoch (train): 100% 51/51 [00:19<00:00,  2.68it/s, dice=0.877, iou=0.781, loss=0.463, loss_bce=0.151, loss_dice=0.123, loss_iou=0.219]\n",
      "[2020-10-18 12:45:11,938] \n",
      "23/100 * Epoch 23 (_base): lr=7.500e-05 | momentum=0.9000\n",
      "23/100 * Epoch 23 (train): dice=0.9139 | iou=0.8432 | loss=0.3577 | loss_bce=0.1435 | loss_dice=0.0861 | loss_iou=0.1568\n",
      "24/100 * Epoch (train): 100% 51/51 [00:19<00:00,  2.67it/s, dice=0.946, iou=0.898, loss=0.232, loss_bce=0.095, loss_dice=0.054, loss_iou=0.102]\n",
      "[2020-10-18 12:45:32,069] \n",
      "24/100 * Epoch 24 (_base): lr=7.500e-05 | momentum=0.9000\n",
      "24/100 * Epoch 24 (train): dice=0.9159 | iou=0.8469 | loss=0.3528 | loss_bce=0.1445 | loss_dice=0.0841 | loss_iou=0.1531\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/100 * Epoch (train): 100% 51/51 [00:18<00:00,  2.83it/s, dice=0.810, iou=0.681, loss=0.797, loss_bce=0.360, loss_dice=0.190, loss_iou=0.319]\n",
      "[2020-10-18 12:45:51,163] \n",
      "25/100 * Epoch 25 (_base): lr=7.500e-05 | momentum=0.9000\n",
      "25/100 * Epoch 25 (train): dice=0.9176 | iou=0.8495 | loss=0.3456 | loss_bce=0.1408 | loss_dice=0.0824 | loss_iou=0.1505\n",
      "26/100 * Epoch (train): 100% 51/51 [00:18<00:00,  2.83it/s, dice=0.915, iou=0.842, loss=0.372, loss_bce=0.161, loss_dice=0.085, loss_iou=0.158]\n",
      "[2020-10-18 12:46:10,160] \n",
      "26/100 * Epoch 26 (_base): lr=7.500e-05 | momentum=0.9000\n",
      "26/100 * Epoch 26 (train): dice=0.9224 | iou=0.8575 | loss=0.3251 | loss_bce=0.1311 | loss_dice=0.0776 | loss_iou=0.1425\n",
      "27/100 * Epoch (train): 100% 51/51 [00:17<00:00,  2.84it/s, dice=0.897, iou=0.814, loss=0.466, loss_bce=0.222, loss_dice=0.103, loss_iou=0.186]\n",
      "[2020-10-18 12:46:29,201] \n",
      "27/100 * Epoch 27 (_base): lr=7.500e-05 | momentum=0.9000\n",
      "27/100 * Epoch 27 (train): dice=0.9193 | iou=0.8522 | loss=0.3448 | loss_bce=0.1453 | loss_dice=0.0807 | loss_iou=0.1478\n",
      "28/100 * Epoch (train): 100% 51/51 [00:18<00:00,  2.83it/s, dice=0.957, iou=0.918, loss=0.184, loss_bce=0.073, loss_dice=0.043, loss_iou=0.082]\n",
      "[2020-10-18 12:46:47,868] \n",
      "28/100 * Epoch 28 (_base): lr=7.500e-05 | momentum=0.9000\n",
      "28/100 * Epoch 28 (train): dice=0.9169 | iou=0.8482 | loss=0.3532 | loss_bce=0.1479 | loss_dice=0.0831 | loss_iou=0.1518\n",
      "29/100 * Epoch (train): 100% 51/51 [00:17<00:00,  2.84it/s, dice=0.938, iou=0.884, loss=0.262, loss_bce=0.106, loss_dice=0.062, loss_iou=0.116]\n",
      "[2020-10-18 12:47:06,528] \n",
      "29/100 * Epoch 29 (_base): lr=7.500e-05 | momentum=0.9000\n",
      "29/100 * Epoch 29 (train): dice=0.9160 | iou=0.8464 | loss=0.3552 | loss_bce=0.1469 | loss_dice=0.0840 | loss_iou=0.1536\n",
      "30/100 * Epoch (train): 100% 51/51 [00:18<00:00,  2.83it/s, dice=0.899, iou=0.816, loss=0.429, loss_bce=0.180, loss_dice=0.101, loss_iou=0.184]\n",
      "[2020-10-18 12:47:25,195] \n",
      "30/100 * Epoch 30 (_base): lr=1.875e-05 | momentum=0.9000\n",
      "30/100 * Epoch 30 (train): dice=0.9188 | iou=0.8518 | loss=0.3388 | loss_bce=0.1368 | loss_dice=0.0812 | loss_iou=0.1482\n",
      "31/100 * Epoch (train): 100% 51/51 [00:18<00:00,  2.82it/s, dice=0.907, iou=0.830, loss=0.402, loss_bce=0.174, loss_dice=0.093, loss_iou=0.170]\n",
      "[2020-10-18 12:47:43,903] \n",
      "31/100 * Epoch 31 (_base): lr=1.875e-05 | momentum=0.9000\n",
      "31/100 * Epoch 31 (train): dice=0.9235 | iou=0.8597 | loss=0.3280 | loss_bce=0.1389 | loss_dice=0.0765 | loss_iou=0.1403\n",
      "32/100 * Epoch (train): 100% 51/51 [00:18<00:00,  2.83it/s, dice=0.928, iou=0.866, loss=0.287, loss_bce=0.101, loss_dice=0.072, loss_iou=0.134]\n",
      "[2020-10-18 12:48:02,946] \n",
      "32/100 * Epoch 32 (_base): lr=1.875e-05 | momentum=0.9000\n",
      "32/100 * Epoch 32 (train): dice=0.9179 | iou=0.8503 | loss=0.3429 | loss_bce=0.1388 | loss_dice=0.0821 | loss_iou=0.1497\n",
      "33/100 * Epoch (train): 100% 51/51 [00:18<00:00,  2.83it/s, dice=0.953, iou=0.911, loss=0.203, loss_bce=0.083, loss_dice=0.047, loss_iou=0.089]\n",
      "[2020-10-18 12:48:21,606] \n",
      "33/100 * Epoch 33 (_base): lr=1.875e-05 | momentum=0.9000\n",
      "33/100 * Epoch 33 (train): dice=0.9259 | iou=0.8644 | loss=0.3066 | loss_bce=0.1212 | loss_dice=0.0741 | loss_iou=0.1356\n",
      "34/100 * Epoch (train): 100% 51/51 [00:18<00:00,  2.82it/s, dice=0.938, iou=0.883, loss=0.249, loss_bce=0.087, loss_dice=0.062, loss_iou=0.117]\n",
      "[2020-10-18 12:48:40,651] \n",
      "34/100 * Epoch 34 (_base): lr=1.875e-05 | momentum=0.9000\n",
      "34/100 * Epoch 34 (train): dice=0.9200 | iou=0.8538 | loss=0.3383 | loss_bce=0.1402 | loss_dice=0.0800 | loss_iou=0.1462\n",
      "35/100 * Epoch (train): 100% 51/51 [00:19<00:00,  2.63it/s, dice=0.901, iou=0.821, loss=0.343, loss_bce=0.081, loss_dice=0.099, loss_iou=0.179]\n",
      "[2020-10-18 12:49:00,752] \n",
      "35/100 * Epoch 35 (_base): lr=1.875e-05 | momentum=0.9000\n",
      "35/100 * Epoch 35 (train): dice=0.9245 | iou=0.8609 | loss=0.3115 | loss_bce=0.1212 | loss_dice=0.0755 | loss_iou=0.1391\n",
      "36/100 * Epoch (train): 100% 51/51 [00:18<00:00,  2.82it/s, dice=0.956, iou=0.916, loss=0.194, loss_bce=0.082, loss_dice=0.044, loss_iou=0.084]\n",
      "[2020-10-18 12:49:19,478] \n",
      "36/100 * Epoch 36 (_base): lr=1.875e-05 | momentum=0.9000\n",
      "36/100 * Epoch 36 (train): dice=0.9284 | iou=0.8672 | loss=0.3022 | loss_bce=0.1223 | loss_dice=0.0716 | loss_iou=0.1328\n",
      "37/100 * Epoch (train): 100% 51/51 [00:18<00:00,  2.83it/s, dice=0.964, iou=0.931, loss=0.145, loss_bce=0.051, loss_dice=0.036, loss_iou=0.069]\n",
      "[2020-10-18 12:49:38,538] \n",
      "37/100 * Epoch 37 (_base): lr=1.875e-05 | momentum=0.9000\n",
      "37/100 * Epoch 37 (train): dice=0.9236 | iou=0.8596 | loss=0.3271 | loss_bce=0.1379 | loss_dice=0.0764 | loss_iou=0.1404\n",
      "38/100 * Epoch (train): 100% 51/51 [00:18<00:00,  2.81it/s, dice=0.895, iou=0.809, loss=0.491, loss_bce=0.244, loss_dice=0.105, loss_iou=0.191]\n",
      "[2020-10-18 12:49:57,354] \n",
      "38/100 * Epoch 38 (_base): lr=1.875e-05 | momentum=0.9000\n",
      "38/100 * Epoch 38 (train): dice=0.9306 | iou=0.8712 | loss=0.2912 | loss_bce=0.1162 | loss_dice=0.0694 | loss_iou=0.1288\n",
      "39/100 * Epoch (train): 100% 51/51 [00:18<00:00,  2.81it/s, dice=0.778, iou=0.637, loss=0.839, loss_bce=0.317, loss_dice=0.222, loss_iou=0.363]\n",
      "[2020-10-18 12:50:16,459] \n",
      "39/100 * Epoch 39 (_base): lr=1.875e-05 | momentum=0.9000\n",
      "39/100 * Epoch 39 (train): dice=0.9257 | iou=0.8635 | loss=0.3173 | loss_bce=0.1331 | loss_dice=0.0743 | loss_iou=0.1365\n",
      "40/100 * Epoch (train): 100% 51/51 [00:18<00:00,  2.78it/s, dice=0.949, iou=0.903, loss=0.226, loss_bce=0.098, loss_dice=0.051, loss_iou=0.097]\n",
      "[2020-10-18 12:50:35,472] \n",
      "40/100 * Epoch 40 (_base): lr=1.875e-05 | momentum=0.9000\n",
      "40/100 * Epoch 40 (train): dice=0.9295 | iou=0.8693 | loss=0.2988 | loss_bce=0.1220 | loss_dice=0.0705 | loss_iou=0.1307\n",
      "41/100 * Epoch (train): 100% 51/51 [00:18<00:00,  2.80it/s, dice=0.838, iou=0.722, loss=0.704, loss_bce=0.329, loss_dice=0.162, loss_iou=0.278]\n",
      "[2020-10-18 12:50:54,415] \n",
      "41/100 * Epoch 41 (_base): lr=1.875e-05 | momentum=0.9000\n",
      "41/100 * Epoch 41 (train): dice=0.9312 | iou=0.8722 | loss=0.2889 | loss_bce=0.1154 | loss_dice=0.0688 | loss_iou=0.1278\n",
      "42/100 * Epoch (train): 100% 51/51 [00:18<00:00,  2.72it/s, dice=0.918, iou=0.849, loss=0.344, loss_bce=0.139, loss_dice=0.082, loss_iou=0.151]\n",
      "[2020-10-18 12:51:14,226] \n",
      "42/100 * Epoch 42 (_base): lr=1.875e-05 | momentum=0.9000\n",
      "42/100 * Epoch 42 (train): dice=0.9254 | iou=0.8625 | loss=0.3204 | loss_bce=0.1353 | loss_dice=0.0746 | loss_iou=0.1375\n",
      "43/100 * Epoch (train): 100% 51/51 [00:18<00:00,  2.75it/s, dice=0.933, iou=0.875, loss=0.283, loss_bce=0.114, loss_dice=0.067, loss_iou=0.125]\n",
      "[2020-10-18 12:51:33,596] \n",
      "43/100 * Epoch 43 (_base): lr=1.875e-05 | momentum=0.9000\n",
      "43/100 * Epoch 43 (train): dice=0.9291 | iou=0.8688 | loss=0.3007 | loss_bce=0.1233 | loss_dice=0.0709 | loss_iou=0.1312\n",
      "44/100 * Epoch (train): 100% 51/51 [00:19<00:00,  2.67it/s, dice=0.844, iou=0.730, loss=0.775, loss_bce=0.436, loss_dice=0.156, loss_iou=0.270]\n",
      "[2020-10-18 12:51:53,384] \n",
      "44/100 * Epoch 44 (_base): lr=1.875e-05 | momentum=0.9000\n",
      "44/100 * Epoch 44 (train): dice=0.9276 | iou=0.8662 | loss=0.3103 | loss_bce=0.1301 | loss_dice=0.0724 | loss_iou=0.1338\n",
      "45/100 * Epoch (train): 100% 51/51 [00:19<00:00,  2.59it/s, dice=0.884, iou=0.793, loss=0.466, loss_bce=0.179, loss_dice=0.116, loss_iou=0.207]\n",
      "[2020-10-18 12:52:13,877] \n",
      "45/100 * Epoch 45 (_base): lr=4.687e-06 | momentum=0.9000\n",
      "45/100 * Epoch 45 (train): dice=0.9297 | iou=0.8697 | loss=0.2958 | loss_bce=0.1190 | loss_dice=0.0703 | loss_iou=0.1303\n",
      "46/100 * Epoch (train): 100% 51/51 [00:19<00:00,  2.61it/s, dice=0.972, iou=0.946, loss=0.107, loss_bce=0.032, loss_dice=0.028, loss_iou=0.054]\n",
      "[2020-10-18 12:52:34,123] \n",
      "46/100 * Epoch 46 (_base): lr=4.687e-06 | momentum=0.9000\n",
      "46/100 * Epoch 46 (train): dice=0.9314 | iou=0.8729 | loss=0.2911 | loss_bce=0.1192 | loss_dice=0.0686 | loss_iou=0.1271\n",
      "47/100 * Epoch (train): 100% 51/51 [00:19<00:00,  2.61it/s, dice=0.939, iou=0.885, loss=0.256, loss_bce=0.100, loss_dice=0.061, loss_iou=0.115]\n",
      "[2020-10-18 12:52:55,055] \n",
      "47/100 * Epoch 47 (_base): lr=4.687e-06 | momentum=0.9000\n",
      "47/100 * Epoch 47 (train): dice=0.9232 | iou=0.8590 | loss=0.3194 | loss_bce=0.1270 | loss_dice=0.0768 | loss_iou=0.1410\n",
      "48/100 * Epoch (train): 100% 51/51 [00:18<00:00,  2.70it/s, dice=0.953, iou=0.910, loss=0.185, loss_bce=0.060, loss_dice=0.047, loss_iou=0.090]\n",
      "[2020-10-18 12:53:14,795] \n",
      "48/100 * Epoch 48 (_base): lr=4.687e-06 | momentum=0.9000\n",
      "48/100 * Epoch 48 (train): dice=0.9248 | iou=0.8617 | loss=0.3167 | loss_bce=0.1291 | loss_dice=0.0752 | loss_iou=0.1383\n",
      "49/100 * Epoch (train): 100% 51/51 [00:18<00:00,  2.72it/s, dice=0.952, iou=0.909, loss=0.189, loss_bce=0.063, loss_dice=0.048, loss_iou=0.091]\n",
      "[2020-10-18 12:53:34,446] \n",
      "49/100 * Epoch 49 (_base): lr=4.687e-06 | momentum=0.9000\n",
      "49/100 * Epoch 49 (train): dice=0.9231 | iou=0.8605 | loss=0.3216 | loss_bce=0.1316 | loss_dice=0.0769 | loss_iou=0.1395\n",
      "50/100 * Epoch (train): 100% 51/51 [00:18<00:00,  2.69it/s, dice=0.948, iou=0.901, loss=0.226, loss_bce=0.093, loss_dice=0.052, loss_iou=0.099]\n",
      "[2020-10-18 12:53:54,104] \n",
      "50/100 * Epoch 50 (_base): lr=1.172e-06 | momentum=0.9000\n",
      "50/100 * Epoch 50 (train): dice=0.9260 | iou=0.8642 | loss=0.3067 | loss_bce=0.1211 | loss_dice=0.0740 | loss_iou=0.1358\n",
      "51/100 * Epoch (train): 100% 51/51 [00:19<00:00,  2.64it/s, dice=0.939, iou=0.884, loss=0.238, loss_bce=0.077, loss_dice=0.061, loss_iou=0.116]\n",
      "[2020-10-18 12:54:14,301] \n",
      "51/100 * Epoch 51 (_base): lr=1.172e-06 | momentum=0.9000\n",
      "51/100 * Epoch 51 (train): dice=0.9309 | iou=0.8716 | loss=0.2924 | loss_bce=0.1185 | loss_dice=0.0691 | loss_iou=0.1284\n",
      "52/100 * Epoch (train): 100% 51/51 [00:19<00:00,  2.66it/s, dice=0.949, iou=0.903, loss=0.216, loss_bce=0.085, loss_dice=0.051, loss_iou=0.097]\n",
      "[2020-10-18 12:54:35,288] \n",
      "52/100 * Epoch 52 (_base): lr=1.172e-06 | momentum=0.9000\n",
      "52/100 * Epoch 52 (train): dice=0.9247 | iou=0.8615 | loss=0.3270 | loss_bce=0.1415 | loss_dice=0.0753 | loss_iou=0.1385\n",
      "53/100 * Epoch (train): 100% 51/51 [00:19<00:00,  2.62it/s, dice=0.950, iou=0.906, loss=0.206, loss_bce=0.078, loss_dice=0.050, loss_iou=0.094]\n",
      "[2020-10-18 12:54:55,623] \n",
      "53/100 * Epoch 53 (_base): lr=1.172e-06 | momentum=0.9000\n",
      "53/100 * Epoch 53 (train): dice=0.9271 | iou=0.8664 | loss=0.3116 | loss_bce=0.1314 | loss_dice=0.0729 | loss_iou=0.1336\n",
      "Early stop at 53 epoch\n",
      "Top best models:\n",
      "logs/20201018-123740/checkpoints/train.46.pth\t0.8729\n"
     ]
    }
   ],
   "source": [
    "runner.train(\n",
    "    model=model,\n",
    "    criterion=criterion,\n",
    "    optimizer=optimizer,\n",
    "    scheduler=scheduler,\n",
    "    loaders=loaders,\n",
    "    callbacks=callbacks,\n",
    "    logdir=Path(\"logs\") / datetime.now().strftime(\"%Y%m%d-%H%M%S\"),\n",
    "    num_epochs=100,\n",
    "    main_metric=\"iou\", # kaggle competition metric\n",
    "    minimize_metric=False,\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "37ume7Q1EFxq",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Submission\n",
    "\n",
    "To generate submission, you'll have to write masks for images.\n",
    "Usually, in `Kaggle` segmentation competitions masks are encoded in the run length format.\n",
    "For more information, check `Evaluation` page in `Overview`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "8KHg4nnF-_F9"
   },
   "outputs": [],
   "source": [
    "def rle_encoding(x):\n",
    "    \"\"\"\n",
    "    x: numpy array of shape (height, width), 1 - mask, 0 - background\n",
    "    Returns run length as list\n",
    "    \"\"\"\n",
    "    dots = np.where(x.T.flatten() == 1)[\n",
    "        0\n",
    "    ]  # .T sets Fortran order down-then-right\n",
    "    run_lengths = []\n",
    "    prev = -2\n",
    "    for b in dots:\n",
    "        if b > prev + 1:\n",
    "            run_lengths.extend((b + 1, 0))\n",
    "        run_lengths[-1] += 1\n",
    "        prev = b\n",
    "    return \" \".join([str(i) for i in run_lengths])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uwVgpY2cEFxv"
   },
   "source": [
    "This code below will generate a submission.\n",
    "It reads images from `test` folder and gathers prediction from the trained model.\n",
    "Check your submission before uploading it into `Kaggle`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "Y9_GuIdy3VaY"
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import pandas as pd\n",
    "\n",
    "submission = {\"ImageId\": [], \"EncodedPixels\": []}\n",
    "threshold = 0.5\n",
    "\n",
    "test_transform = albu.Compose([\n",
    "    albu.Resize(IMAGE_SIZE, IMAGE_SIZE),\n",
    "    albu.Normalize(),\n",
    "    ToTensor()\n",
    "])\n",
    "\n",
    "\n",
    "test_image_path = local_path / 'data3' / Path(\"test\")\n",
    "TEST_IMAGES = sorted(test_image_path.glob(\"*.png\"))\n",
    "test_dataset = SegmentationDataset(\n",
    "    images=TEST_IMAGES,\n",
    "    transforms=test_transform\n",
    ")\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=num_workers,\n",
    ")\n",
    "\n",
    "for prediction in runner.predict_loader(loader=test_loader):\n",
    "    submission[\"ImageId\"].extend(s[:-4] for s in prediction[\"filename\"])\n",
    "    submission[\"EncodedPixels\"].extend(\n",
    "        rle_encoding(torch.sigmoid(mask.cpu()).numpy().squeeze(0) > threshold) for mask in prediction[\"mask\"]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(submission).to_csv(f\"sub_seg_{str(datetime.now().strftime('%Y%m%d-%H%M%S'))}.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "segmentation_baseline.ipynb",
   "private_outputs": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
